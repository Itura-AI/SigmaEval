{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Getting Started with SigmaEval\n",
        "\n",
        "This notebook demonstrates a minimal, complete example of how to use `SigmaEval` to evaluate a simple chat application.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, you'll need to provide an API key for the LLM that will be used to judge the application's responses. `SigmaEval` uses [LiteLLM](https://litellm.ai/) to support over 100+ LLM providers, so you can use any model from providers like OpenAI, Anthropic, Google, etc.\n",
        "\n",
        "To set the API key securely in Colab, click the \"ðŸ”‘\" icon in the left-hand sidebar and create a new secret with the name `GEMINI_API_KEY` and your key as the value. Then, run the cell below to load the key into the environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"GEMINI_API_KEY\"] = userdata.get(\"GEMINI_API_KEY\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install sigmaeval\n",
        "%pip install sigmaeval-framework\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ðŸ”„ **Action Required**: After installing the package, you may need to restart the runtime for the changes to take effect. You can do this by clicking `Runtime > Restart runtime` in the Colab menu.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sigmaeval import SigmaEval, ScenarioTest, assertions\n",
        "import asyncio\n",
        "import os\n",
        "\n",
        "# 1. Define the ScenarioTest to describe the desired behavior\n",
        "scenario = (\n",
        "    ScenarioTest(\"Simple Test\")\n",
        "    .given(\"A user interacting with a chatbot\")\n",
        "    .when(\"The user greets the bot\")\n",
        "    .expect_behavior(\n",
        "        \"The bot provides a simple and friendly greeting.\",\n",
        "        # We want to be confident that at least 75% of responses will score an 7/10 or higher.\n",
        "        criteria=assertions.scores.proportion_gte(min_score=7, proportion=0.75)\n",
        "    )\n",
        "    .max_turns(1) # Only needed here since we're returning a static greeting\n",
        ")\n",
        "# 2. Implement the app_handler to allow SigmaEval to communicate with your app\n",
        "async def app_handler(messages, state):\n",
        "    # In a real test, you would pass messages to your app and return the response.\n",
        "    # For this example, we'll return a static, friendly greeting.\n",
        "    return \"Hello there! Nice to meet you!\"\n",
        "\n",
        "# 3. Initialize SigmaEval and run the evaluation\n",
        "async def main():\n",
        "    # You can use any model that LiteLLM supports: https://docs.litellm.ai/docs/providers\n",
        "    sigma_eval = SigmaEval(\n",
        "        judge_model=\"gemini/gemini-2.5-flash\",\n",
        "        sample_size=20,  # The number of times to run the test\n",
        "        significance_level=0.05  # Corresponds to a 95% confidence level\n",
        "    )\n",
        "    result = await sigma_eval.evaluate(scenario, app_handler)\n",
        "    \n",
        "    print(result)\n",
        "    \n",
        "    # Assert that the test passed for integration with testing frameworks\n",
        "    assert result.passed\n",
        "\n",
        "# In a notebook, you can run the async main function directly\n",
        "await main()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
